{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an LSTM model for named entity recognition(NER).  \n",
    "Dataset has been attached with this email or you can use any other publicly available datasets for NER.\n",
    "You can find more information about dataset in the link provided. you are free to choose any library.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from read_data import read_data\n",
    "from preproc import *\n",
    "from dataloader import get_dls, Dataset\n",
    "from model import Model, model_output\n",
    "from training_loop import training_loop\n",
    "from utils import classificationreport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the above files for code in detail. I share only the process in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded the data from https://github.com/davidsbatista/NER-datasets/tree/master/CONLL2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the function read_data from the python file read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentence_tags = read_data('data/train.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n",
       " ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sentence_tags[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total vocabulary and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No preprocessing is done on individual words because for ner task lower casing might hurt.\n",
    "Lemmatization and Stemming could be helpful, but are easy for a deep learning model to figure for itselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabtoidx, labeltoidx = vocab_to_idx(training_sentence_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocabtoidx is a dictionary which converts any word to a index (within the training data vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocabtoidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabtoidx['The']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labeltoidx is a dictionary which converts given label to a index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LOC': 6,\n",
       " 'B-MISC': 3,\n",
       " 'B-ORG': 2,\n",
       " 'B-PER': 4,\n",
       " 'I-LOC': 9,\n",
       " 'I-MISC': 8,\n",
       " 'I-ORG': 7,\n",
       " 'I-PER': 5,\n",
       " 'O': 1,\n",
       " 'pad': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeltoidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert sentences and tags to numerical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function prepare_sentence converts a sentence and the tags  to numerical format using vocabtoidx and labeltoidx dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n",
       " ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sentence_tags[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above sentence is converted to numerical format by following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 3, 4, 5, 6, 7, 8, 9, 10], [2, 1, 3, 1, 1, 1, 3, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sentence_tags(training_sentence_tags[1], vocabtoidx, labeltoidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function prepare batch converts entire dataset into numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=list(prepare_batch(training_sentence_tags, vocabtoidx, labeltoidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1], [1]),\n",
       " ([2, 3, 4, 5, 6, 7, 8, 9, 10], [2, 1, 3, 1, 1, 1, 3, 1, 1]),\n",
       " ([11, 12], [4, 5])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]  ### first three sentences have turned into following format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I intend to build the model using pytorch.  \n",
    "To pass the data into pytorch model we should use pytorch dataloader(for ease of use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(train_data)\n",
    "train_dl = get_dls(dataset_train, bs=16) ## this function gives me the dataloader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've passed a collate funtion to dataloader to make sure that each batch is of equal sized by padding each sentence\n",
    "in a batch to the length of longest sentence in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1,   0,   0,  ...,   0,   0,   0],\n",
       "         [  2,   3,   4,  ...,   0,   0,   0],\n",
       "         [ 11,  12,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [ 15, 349, 350,  ...,   0,   0,   0],\n",
       "         [  1,   0,   0,  ...,   0,   0,   0],\n",
       "         [355, 356, 357,  ...,   0,   0,   0]]),\n",
       " tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [2, 1, 3,  ..., 0, 0, 0],\n",
       "         [4, 5, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [6, 1, 6,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sentence_tags = read_data('data/valid.txt')\n",
    "dataset_valid = Dataset(list(prepare_batch(valid_sentence_tags, vocabtoidx, labeltoidx)))\n",
    "valid_dl = get_dls(dataset_valid, 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've experimented with different hyper parameters in another notebook and found out what works the best on validation data.   \n",
    "These default options I've used in the main file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(vocabtoidx, len(labeltoidx), 128, 128, pretrained=False, freeze=False).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a very simple lstm model shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (emb): Embedding(23627, 128)\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (linear): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss() ## Since this is a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(net.parameters(), 1e1) ## optimiser which applies gradients to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5 ## I haven't implemented early stopping. Something for future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:0.404 Train accuracy:0.837 Valid loss:0.181 Valid accuracy:0.870\n",
      "Train loss:0.131 Train accuracy:0.917 Valid loss:0.142 Valid accuracy:0.909\n",
      "Train loss:0.079 Train accuracy:0.949 Valid loss:0.120 Valid accuracy:0.923\n",
      "Train loss:0.049 Train accuracy:0.968 Valid loss:0.125 Valid accuracy:0.930\n",
      "Train loss:0.031 Train accuracy:0.979 Valid loss:0.125 Valid accuracy:0.930\n"
     ]
    }
   ],
   "source": [
    "training_loop(net, opt, loss_func, epochs, train_dl, valid_dl, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Validation and Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.99      0.97     42973\n",
      "       B-ORG       0.75      0.61      0.67      1340\n",
      "      B-MISC       0.80      0.66      0.73       922\n",
      "       B-PER       0.74      0.64      0.69      1842\n",
      "       I-PER       0.88      0.58      0.70      1307\n",
      "       B-LOC       0.86      0.76      0.81      1837\n",
      "       I-ORG       0.73      0.55      0.63       750\n",
      "      I-MISC       0.63      0.58      0.60       346\n",
      "       I-LOC       0.77      0.67      0.72       257\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     51574\n",
      "   macro avg       0.79      0.67      0.72     51574\n",
      "weighted avg       0.93      0.93      0.93     51574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct, predicted = model_output(net, valid_dl)\n",
    "print(classificationreport(correct.cpu(), predicted.cpu(), target_names=list(zip(*labeltoidx.items()))[0][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence_tags = read_data('data/test.txt')\n",
    "dataset_test = Dataset(list(prepare_batch(test_sentence_tags, vocabtoidx, labeltoidx)))\n",
    "test_dl = get_dls(dataset_test, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.94      0.98      0.96     38520\n",
      "       B-ORG       0.74      0.50      0.59      1660\n",
      "      B-MISC       0.70      0.56      0.62       701\n",
      "       B-PER       0.56      0.53      0.55      1616\n",
      "       I-PER       0.77      0.38      0.51      1156\n",
      "       B-LOC       0.81      0.73      0.77      1667\n",
      "       I-ORG       0.70      0.55      0.62       834\n",
      "      I-MISC       0.46      0.61      0.53       214\n",
      "       I-LOC       0.68      0.49      0.57       257\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     46625\n",
      "   macro avg       0.71      0.59      0.63     46625\n",
      "weighted avg       0.90      0.91      0.90     46625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct, predicted = model_output(net, test_dl)\n",
    "print(classificationreport(correct.cpu(), predicted.cpu(), target_names=list(zip(*labeltoidx.items()))[0][:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test is performing close to the performance of validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note the performance can change a little bit with each run.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lot of optimisations can be done. \n",
    "* Early stopping can be implemented. \n",
    "* Bidirectional Lstm can be used. Deeper LSTM's can be used'\n",
    "* BILSTM-CRF will probably give much better result.\n",
    "* The hyperparameters are tuned for random embeddings. They can be tuned together with pretrained embeddings to get better score\n",
    "* POS tags can be used as input to a linear layer which can then be used for better results. \n",
    "* Trained word embeddings can be visualised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
